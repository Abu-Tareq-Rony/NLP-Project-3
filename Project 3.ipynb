{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e0a26a-8b6e-4346-98fd-b0bebb69657b",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:blue; font-weight:bold;\">T5 Small Model</span></h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e639df-fabc-46a0-bfdf-9983f577e2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    T5TokenizerFast,\n",
    "    T5ForConditionalGeneration,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "import pandas as pd\n",
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from evaluate import load\n",
    "import torch\n",
    "\n",
    "with open(\"QTL_text.json\") as f:\n",
    "    raw = json.load(f)\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "df = df.drop(columns=[\"PMID\", \"Journal\", \"Category\"], errors=\"ignore\")\n",
    "df = df.dropna(subset=[\"Abstract\", \"Title\"]).reset_index(drop=True)\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_pandas(train_df),\n",
    "        \"validation\": Dataset.from_pandas(val_df),\n",
    "    }\n",
    ")\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5TokenizerFast.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "max_input_len = 256\n",
    "max_target_len = 64\n",
    "\n",
    "tokenized = datasets.map(\n",
    "    lambda batch: {\n",
    "        **tokenizer(\n",
    "            [f\"generate title: {t}\" for t in batch[\"Abstract\"]],\n",
    "            max_length=max_input_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "        ),\n",
    "        \"labels\": tokenizer(\n",
    "            batch[\"Title\"],\n",
    "            max_length=max_target_len,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "        )[\"input_ids\"],\n",
    "    },\n",
    "    batched=True,\n",
    "    remove_columns=[\"Abstract\", \"Title\"],\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"t5_small_title_gen\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=max_target_len,\n",
    "    generation_num_beams=8,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=4,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "val_abstracts = val_df[\"Abstract\"].fillna(\"\").tolist()\n",
    "val_inputs = [f\"generate title: {a}\" for a in val_abstracts]\n",
    "\n",
    "all_val_preds = []\n",
    "batch_size = 8\n",
    "\n",
    "for i in range(0, len(val_inputs), batch_size):\n",
    "    batch = val_inputs[i : i + batch_size]\n",
    "    enc = tokenizer(\n",
    "        batch,\n",
    "        max_length=max_input_len,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            input_ids=enc[\"input_ids\"],\n",
    "            attention_mask=enc[\"attention_mask\"],\n",
    "            max_length=max_target_len,\n",
    "            num_beams=8,\n",
    "        )\n",
    "\n",
    "    preds = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "    all_val_preds.extend(preds)\n",
    "\n",
    "val_refs = val_df[\"Title\"].tolist()\n",
    "\n",
    "bleu = load(\"bleu\")\n",
    "val_bleu = bleu.compute(\n",
    "    predictions=all_val_preds,\n",
    "    references=[[r] for r in val_refs],\n",
    ")[\"bleu\"] * 100\n",
    "print(f\"\\nDev BLEU: {val_bleu:.2f}\")\n",
    "\n",
    "rouge = load(\"rouge\")\n",
    "val_rouge = rouge.compute(\n",
    "    predictions=all_val_preds,\n",
    "    references=val_refs,\n",
    "    rouge_types=[\"rouge2\", \"rougeL\"],\n",
    ")\n",
    "print(f\"Dev ROUGE-2: {val_rouge['rouge2']:.4f}\")\n",
    "print(f\"Dev ROUGE-L: {val_rouge['rougeL']:.4f}\")\n",
    "\n",
    "test_df = pd.read_csv(\"QTL_test_labeled.tsv\", sep=\"\\t\")\n",
    "test_abstracts = test_df[\"Abstract\"].fillna(\"\").tolist()\n",
    "test_inputs = [f\"generate title: {a}\" for a in test_abstracts]\n",
    "\n",
    "test_preds = []\n",
    "\n",
    "for i in range(0, len(test_inputs), batch_size):\n",
    "    batch = test_inputs[i : i + batch_size]\n",
    "    enc = tokenizer(\n",
    "        batch,\n",
    "        max_length=max_input_len,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            input_ids=enc[\"input_ids\"],\n",
    "            attention_mask=enc[\"attention_mask\"],\n",
    "            max_length=max_target_len,\n",
    "            num_beams=8,\n",
    "        )\n",
    "\n",
    "    preds = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "    test_preds.extend(preds)\n",
    "\n",
    "test_df[\"Predicted_Title\"] = test_preds\n",
    "\n",
    "test_refs = test_df[\"Title\"].fillna(\"\").tolist()\n",
    "\n",
    "test_bleu = bleu.compute(\n",
    "    predictions=test_preds,\n",
    "    references=[[r] for r in test_refs],\n",
    ")[\"bleu\"] * 100\n",
    "print(f\"\\nTEST BLEU: {test_bleu:.2f}\")\n",
    "\n",
    "test_rouge = rouge.compute(\n",
    "    predictions=test_preds,\n",
    "    references=test_refs,\n",
    "    rouge_types=[\"rouge2\", \"rougeL\"],\n",
    ")\n",
    "print(f\"TEST ROUGE-2: {test_rouge['rouge2']:.4f}\")\n",
    "print(f\"TEST ROUGE-L: {test_rouge['rougeL']:.4f}\")\n",
    "\n",
    "test_df.to_csv(\"QTL_test_with_predicted_titles.tsv\", sep=\"\\t\", index=False)\n",
    "print(\"Test predictions saved to QTL_test_with_predicted_titles.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc43cc89-068a-41f6-bc05-977f10598669",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:blue; font-weight:bold;\">Mistral 7B</span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27207e17-a716-4707-8c46-1a9928f9db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import evaluate\n",
    "\n",
    "# basic config\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "TRAIN_FILE = \"QTL_text.json\"\n",
    "TEST_FILE  = \"QTL_test_labeled.tsv\"\n",
    "\n",
    "DEV_OUTPUT_FILE  = \"mistral_dev_zero_shot_10shot.tsv\"\n",
    "TEST_OUTPUT_FILE = \"mistral_test_zero_shot_10shot.tsv\"\n",
    "\n",
    "MAX_GEN_LEN = 32\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "USE_CPU_ONLY = False\n",
    "\n",
    "# load train data\n",
    "with open(TRAIN_FILE) as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(raw)\n",
    "df = df.drop(columns=[\"PMID\", \"Journal\", \"Category\"], errors=\"ignore\")\n",
    "df = df.dropna(subset=[\"Abstract\", \"Title\"]).reset_index(drop=True)\n",
    "\n",
    "train_df, dev_df = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\n",
    "dev_data = dev_df.to_dict(orient=\"records\")\n",
    "print(f\"DEV size: {len(dev_data)}\")\n",
    "\n",
    "# few-shot examples\n",
    "n_shots = min(10, len(train_df))\n",
    "few_shot_examples = train_df.sample(n=n_shots, random_state=RANDOM_SEED)[[\"Abstract\", \"Title\"]].to_dict(orient=\"records\")\n",
    "print(f\"Using {n_shots} examples in the prompt.\")\n",
    "\n",
    "# load test data\n",
    "test_df_full = pd.read_csv(TEST_FILE, sep=\"\\t\", header=0)\n",
    "test_data = test_df_full.to_dict(orient=\"records\")\n",
    "print(f\"TEST size: {len(test_data)}\")\n",
    "\n",
    "# load model + tokenizer\n",
    "print(\"Loading Mistral-7B (4-bit)...\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "if USE_CPU_ONLY or not torch.cuda.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(device)\n",
    "    print(\"Model on CPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    print(\"Model on GPU:\", model.device)\n",
    "\n",
    "\n",
    "def truncate_text(text, max_chars):\n",
    "    text = str(text).replace(\"\\n\", \" \")\n",
    "    return text[:max_chars].strip() if len(text) > max_chars else text.strip()\n",
    "\n",
    "\n",
    "def build_prompt(abstract):\n",
    "    parts = []\n",
    "    parts.append(\n",
    "        \"You are an expert biomedical editor. \"\n",
    "        \"Given an abstract, generate a concise scientific title similar to the examples.\\n\"\n",
    "        \"Use around 10â€“18 words.\\n\"\n",
    "    )\n",
    "\n",
    "    for i, ex in enumerate(few_shot_examples, start=1):\n",
    "        ex_abs = truncate_text(ex[\"Abstract\"], 250)\n",
    "        ex_title = truncate_text(ex[\"Title\"], 120)\n",
    "        parts.append(\n",
    "            f\"\\nExample {i}\\n\"\n",
    "            f\"Abstract: {ex_abs}\\n\"\n",
    "            f\"Title: {ex_title}\\n\"\n",
    "        )\n",
    "\n",
    "    cur_abs = truncate_text(abstract, 300)\n",
    "    parts.append(\n",
    "        \"\\nNow generate a title.\\n\"\n",
    "        f\"Abstract: {cur_abs}\\n\"\n",
    "        \"Title:\"\n",
    "    )\n",
    "\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "def clean_title(text):\n",
    "    text = text.strip()\n",
    "    if text.lower().startswith(\"title:\"):\n",
    "        text = text[6:].strip()\n",
    "    text = text.split(\"\\n\")[0].strip()\n",
    "    text = text.replace('\"', \"\").rstrip(\".\").strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def generate_title(abstract):\n",
    "    prompt = build_prompt(abstract)\n",
    "    enc = tokenizer(prompt, truncation=True, return_tensors=\"pt\").to(model.device)\n",
    "    input_len = enc[\"input_ids\"].shape[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **enc,\n",
    "            max_new_tokens=MAX_GEN_LEN,\n",
    "            num_beams=1,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    new_tokens = out[0][input_len:]\n",
    "    if new_tokens.numel() > 0:\n",
    "        raw = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "    else:\n",
    "        raw = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "    return clean_title(raw)\n",
    "\n",
    "\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def show_metrics(preds, refs, name):\n",
    "    bleu = bleu_metric.compute(predictions=preds, references=[[r] for r in refs])\n",
    "    rouge = rouge_metric.compute(predictions=preds, references=refs)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"BLEU    : {bleu['bleu']:.4f}\")\n",
    "    print(f\"ROUGE-2 : {rouge['rouge2']:.4f}\")\n",
    "    print(f\"ROUGE-L : {rouge['rougeL']:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\nGenerating DEV titles...\")\n",
    "dev_rows = []\n",
    "for i, d in enumerate(dev_data, start=1):\n",
    "    gen = generate_title(d[\"Abstract\"])\n",
    "    dev_rows.append({\n",
    "        \"Abstract\": d[\"Abstract\"],\n",
    "        \"Title\": d[\"Title\"],\n",
    "        \"GeneratedTitle\": gen\n",
    "    })\n",
    "    if i % 20 == 0 or i == len(dev_data):\n",
    "        print(f\"DEV {i}/{len(dev_data)}\")\n",
    "\n",
    "dev_df_out = pd.DataFrame(dev_rows)\n",
    "dev_df_out.to_csv(DEV_OUTPUT_FILE, sep=\"\\t\", index=False)\n",
    "show_metrics(dev_df_out[\"GeneratedTitle\"].tolist(), dev_df_out[\"Title\"].tolist(), \"DEV (10-shot, full)\")\n",
    "\n",
    "\n",
    "print(\"\\nGenerating TEST titles...\")\n",
    "test_rows = []\n",
    "for i, d in enumerate(test_data, start=1):\n",
    "    gen = generate_title(d[\"Abstract\"])\n",
    "    test_rows.append({\n",
    "        \"Abstract\": d[\"Abstract\"],\n",
    "        \"Title\": d[\"Title\"],\n",
    "        \"GeneratedTitle\": gen\n",
    "    })\n",
    "    if i % 20 == 0 or i == len(test_data):\n",
    "        print(f\"TEST {i}/{len(test_data)}\")\n",
    "\n",
    "test_df_out = pd.DataFrame(test_rows)\n",
    "test_df_out.to_csv(TEST_OUTPUT_FILE, sep=\"\\t\", index=False)\n",
    "show_metrics(test_df_out[\"GeneratedTitle\"].tolist(), test_df_out[\"Title\"].tolist(), \"TEST (10-shot, full)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default-env",
   "language": "python",
   "name": "default-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
